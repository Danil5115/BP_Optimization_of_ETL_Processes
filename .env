# IMPORTANT: This file should be in .gitignore. Use .env.example as a template.

# Ports (change if there's a conflict)
AIRFLOW__PORT=8080
POSTGRES__PORT=5432
SPARK_UI__PORT=4040

# Postgres credentials - CHANGE THESE IN PRODUCTION
POSTGRES_USER=de
POSTGRES_PASSWORD=de_password  # TODO: Use secrets management in production
POSTGRES_DB=postgres

# Airflow
# Fixed training key - GENERATE NEW KEY FOR PRODUCTION using:
# python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__FERNET_KEY=Z0wFv5q1h5Q3bZ8o3B2Y3i8s0V3b0o2l5c6k7p8m2lA=
AIRFLOW__EXECUTOR=LocalExecutor
AIRFLOW__LOAD_EXAMPLES=False
AIRFLOW__WEBSERVER_SECRET_KEY=replace_me_secret  # TODO: Generate secure random key
AIRFLOW_UID=50000

# Paths and images
DATA_ROOT=/opt/etl/data
SPARK_IMAGE=my-spark:latest

# Windows example paths - change to your actual paths
# For Linux/Mac use absolute paths like /home/user/project/data
HOST_DATA_DIR=D:/bp/code_test/BP_Optimization_of_ETL_Processes/data
HOST_SPARK_JOBS_DIR=D:/bp/code_test/BP_Optimization_of_ETL_Processes/spark/jobs